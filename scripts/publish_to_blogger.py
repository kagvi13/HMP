#!/usr/bin/env python3
import os
import json
import hashlib
import time
from googleapiclient.discovery import build
from google.oauth2.credentials import Credentials
import argparse

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ===
SITE_DIR = "site"  # HTML-—Ñ–∞–π–ª—ã –ø–æ—Å–ª–µ mkdocs build
PUBLISHED_FILE = "published_posts.json"
SLEEP_BETWEEN_POSTS = 60  # —Å–µ–∫—É–Ω–¥
BLOG_ID = os.environ.get("BLOG_ID")
TOKEN_FILE = os.environ.get("TOKEN_FILE", "token.pkl")

# === –£—Ç–∏–ª–∏—Ç—ã ===
def md5sum(path):
    with open(path, "rb") as f:
        return hashlib.md5(f.read()).hexdigest()

def load_published():
    if os.path.exists(PUBLISHED_FILE):
        with open(PUBLISHED_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    print("‚ö† published_posts.json –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî –Ω–∞—á–∏–Ω–∞–µ–º —Å –Ω—É–ª—è.")
    return {}

def save_published(data):
    with open(PUBLISHED_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def get_service():
    creds = Credentials.from_authorized_user_file(TOKEN_FILE)
    return build("blogger", "v3", credentials=creds)

# === –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ ===
def publish_site():
    service = get_service()
    published = load_published()

    # —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ html-—Ñ–∞–π–ª—ã
    html_files = []
    for root, _, files in os.walk(SITE_DIR):
        for name in files:
            if name.endswith(".html"):
                path = os.path.join(root, name)
                rel_path = os.path.relpath(path, SITE_DIR)  # –∫–ª—é—á
                html_files.append((rel_path, path))

    for rel_path, path in html_files:
        content_hash = md5sum(path)
        post_meta = published.get(rel_path)

        # —á–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ html
        with open(path, "r", encoding="utf-8") as f:
            html_content = f.read()

        if post_meta and post_meta["hash"] == content_hash:
            print(f"‚è≠ –ü—Ä–æ–ø—É—Å–∫–∞–µ–º {rel_path} ‚Äî –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π")
            continue

        title = os.path.splitext(os.path.basename(rel_path))[0]

        if post_meta:  # –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ—Å—Ç–∞
            post_id = post_meta["id"]
            print(f"üîÑ –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ—Å—Ç {rel_path}")
            post = (
                service.posts()
                .update(
                    blogId=BLOG_ID,
                    postId=post_id,
                    body={"title": title, "content": html_content},
                )
                .execute()
            )
        else:  # –Ω–æ–≤—ã–π –ø–æ—Å—Ç
            print(f"üÜï –ü—É–±–ª–∏–∫—É–µ–º –Ω–æ–≤—ã–π –ø–æ—Å—Ç {rel_path}")
            post = (
                service.posts()
                .insert(
                    blogId=BLOG_ID,
                    body={"title": title, "content": html_content},
                )
                .execute()
            )

        url = post.get("url")
        post_id = post.get("id")
        print(f"‚úÖ {rel_path} ‚Üí {url}")

        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        published[rel_path] = {"id": post_id, "hash": content_hash}
        save_published(published)

        print(f"‚è± –ü–∞—É–∑–∞ {SLEEP_BETWEEN_POSTS} —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º –ø–æ—Å—Ç–æ–º‚Ä¶")
        time.sleep(SLEEP_BETWEEN_POSTS)

if __name__ == "__main__":
    publish_site()
